% !TEX root=foo.tex
\section{Discussion}
\label{sec:discussion}

Our findings from the initial level of coding (binary) is very encouraging. From a complete random sample of data we managed to achieve 51.6\% of total comments those were indicative of some form of \textit{Non-use}. This shows tech-savvy users are resisting usage, lurking or abandoning a large scale well-designed system like Facebook. Even if we think all the comments of Slashdot belong to either one of the class \textit{Non-use} or \textit{not related to Non-use}, which is not the case, the probability of getting a non-user is more than 50\% in our data (which is very high considering the wide range of other topics belonging to the class \textit{not related to Non-use}). The discrepancy between the fact that Facebook's user base is growing\footnote{\url{https://newsroom.fb.com/company-info/}} while we get such a high percentage of expert users who are dissatisfied with Facebook, provides strong evidence to a positive answer to our \emph{RQ1}. 

The second level thematic coding and further analysis attempt to answer \emph{RQ2}. From Table~\ref{table:coding category}, we can see \textit{Facebook Functionality} and \textit{Privacy and Security} are two primary influential factors for Facebook \textit{Non-use} (47.48\% and 32.56\% respectively). This implies that users are dissatisfied with several aspects of Facebook system architecture and other features of Facebook in general. This includes but not limited to Facebook ads, Facebook interface, autoplay video feature of Facebook, fake news spreading, insufficient security measure to user content, Facebook policy, Facebook terms and conditions, the way Facebook uses user data to their benefit etc. The other major concern that the users have is lack of privacy and security measures from Facebook point of view. They don't believe Facebook is a reliable storage of their content. Commenters have a common complain regarding data breach and the fact that Facebook is spying on their activity. According to them, Facebook treats the user content as their property and they sell it for their sake. Another common complain is Facebook access to the user data, for example, contact list of their phone and they frequently data mine user activity based on search history. \textit{Personal Preferences} is the next factor and it accounts for almost 18.6\% of the dataset. It turns out that often times people say, \textit{"I don't care..."} or things like \textit{"It is my choice..."} or \textit{"I hate Facebook because it is wasting my time..."}. So, they are not blaiming anything else rather their attitude indicates that they are deliberately choosing not to use Facebook for some personal reason. Another thing that came up in this regard was, people don't actually think Facebook friends are real friends rather they underscore the importance of getting out and socializing in real life. \textit{Negative Perceptions of Facebook} (14.73\%) was identified when users castigated Facebook (e.g., by using slang or swearing terms, such as "fuck", "shit", "creepy", "sucks" etc.) but did not really mention the specific reason. 

12.98\% of the comments indicated that Facebook users are not particularly happy with the \textit{Audience} of their Facebook activity, such as fake friends, distasteful confrontation among members of any Facebook group, presence of parents in friend list etc. Another form of \textit{Non-use} caused by audience was when users are compelled to use Facebook against their will because they care about their Facebook friends. \textit{Influence of External Factors} plays a role when users are inadvertently forced to stay on Facebook for reasons like just to keep in touch with others, get information about something which otherwise is not possible. Political and government/external interception on Facebook use were also discussed by some users. Some of the users (at least 5.23\%) found some \textit{Non-Facebook Media Use} is more user friendly or a better mode of communication compared to Facebook (e.g., Slack, Instagram, Snapchat, Reddit etc.). 

The wordclouds discussed in previous section complies with the discussion above. A closer look at the unigram wordcloud reveals predominant words like "social", "privacy", "fake", "ad", "data", "news", "personal", "security", "stopped", "deleted" which are associated with comment phrases like "social media", "privacy and security concerns", "fake news", "selling personal data", "stopped using", "deleted account" etc. It also contains sentiment terms, such as "shit", "fuck", "hate" etc. that reflect user aversion. The key terms in the bigram wordcloud in Figure~\ref{fig:figure2}(b) appear to be "fake news", "stop using", "news feed", "personal information", "privacy setting", "delete account". Most visible key phrases of trigram from Figure~\ref{fig:figure2}(c) are: "i don't use", "i don't have", "don't use Facebook", "don't have a", "i don't care", "stop using Facebook". These visualizations are informative, for example, terms like "don't use Facebook" appeared 17 times which implies at least 17 times in a set of 516 comments users are talking about not using Facebook. All these wordclouds gives us a top level idea of if people are rejecting Facebook and why. 

The interpretation of LDA and NMF topics reported in Table~\ref{tab:table3} and Table~\ref{tab:table4} also supports our findings so far. Top words associated with each topic assumes the corpus is a mixture of these topics. Table~\ref{tab:table3} shows the topic words useful for our analysis; for example "hate", "privacy" in (Topic 1), "news", "ads", "block" in (Topic 2), "data", "private" in (Topic 3), "privacy", "information" in (Topic 4), "stopped", "left", "dropped" in (Topic 5), "social", "personal" in (Topic 6), "deleted", "fake", "stop" in (Topic 7), "money", "problem" in (Topic 8) etc. The NMF based approach (Table~\ref{tab:table4} (highlighted)) extracts somewhat similar topics other than few exceptions like "networking", "friend", "private", "hell", "shit", "hate", "share" etc. The repetition of similar words indicates that the manual coding criteria adopted by the coders and automated analysis tend to converge. This is exciting because that answers our \textit{RQ2} and it has practical implications for large scale analysis that will be discussed in Implications section.

The sentiment box plots (Figure~\ref{fig:figure6}) reveal median compound scores overall and for each theme. The overall distribution of scores is fairly symmetric (mean of .007) with 240 out of 516 (46.51\%) comments are marked as negative by VADER. This gives a rough idea of overall sentiments of all comments, however, that does not tell the distribution of positive/negative comments according to each thematic category. We can see that out of all thematic categories, \textit{Negative Perspective of Facebook} has the lowest median score (negative) which means comments of this theme are more associated with negative sentiment compared to any other theme (the lower the score, the more negative it is). It is expected because these comments are associated with slang and swearing terms. From Table ~\ref{tab:table5}, 55.26\% of the comments of this category have somewhat negative sentiment. This category also holds the most negative score or most negative comment (score -0.97). Although the box plot has long tail on the right (indicating few positive scores), the median is closer to third quartile so there is no conclusive evidence on the skewness.  In general, other themes that have median scores below 0 (meaning more negative) include \textit{Audience} and \textit{Facebook Functionality} (53.73\% and 51.42\% negativity respectively). The distribution of both these themes are skewed to right which explains the dominance of negativity. The most positive theme with a mean score of 0.16 is \textit{Personal Preferences} and that is explained by the fact that most of the comments of this theme do not involve harsh criticism or negative terms (just personal feelings). The box plot also indicate that the scores of this theme are skewed to left with mean (0.16) < median (0.24). The same argument also holds for \textit{Non-Facebook Media Use} and \textit{Modified Behavior} which have relatively higher compound score. The distribution of these two theme scores are skewed to left too, meaning more positivity. From the box plots, it is obvious that \textit{Influence of External Factors} theme is most symmetrically distributed. Although from Table ~\ref{tab:table5}, it shows the percentage negativity of comments of this theme is 43.1\%, we can see there are 16 extremely negative comments which is pulling the mean score down.

% The results of logistic regression classifier is reported in Table ~\ref{tab:table5}. The interpretation of results of VADER tool does not give a clear idea of how many negative comments belong to each theme because the definition of positiveness and negativeness is dependent upon a normalized score which can be interpreted in different ways. The machine learning approach, although not trained with domain specific data, gives a rough idea of what is the percentage of comments those are more negative per theme. From the results we can see the highest negative comments are from \textit{Non-Facebook Media Use}, \textit{Personal Preferences} and \textit{Audience} respectively. We assume this is because our negative training examples had more similarity with comments from these themes. Incorporating more data for training and using more  sophisticated parameters like Random Forests might be more meaningful which we leave as future work.