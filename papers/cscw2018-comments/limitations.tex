% !TEX root=nonusecomments.tex
\section{Limitations}
\label{sec:limitations}
We randomly sampled 2000 comments from Slashdot \& 1000 comments from Schneier's blog and tried to answer our questions from those comments only. It is arguable that if these comments are representative of the whole mass or not; therefore if the findings can be concluded as generic with same level of certainty. The whole point of random sampling was to get unrelated and unbiased data. We acknowledge the fact that, there are more (in terms of social media \emph{Non-use} \& \emph{NS} motives) than what we have discovered due to the lack of sample. This is also why we could do not any significance test to confirm the \textit{RQ1} findings. While analyzing the data we noticed that the comments often involve multiple words including positive and negative words, however the sarcastic tone altered the meaning completely. It is the inherent ambiguity in human language that makes the analysis fuzzy at times which we tried to overcome to the best of our discretion.

One point of argument can be what is the explicit definition of "expertise" since we claimed Slashdotters and Schneier's blog users are tech-savvy expert population. There is no way of confirming that unless we have the users profile which is not feasible. But it is the type of blog and the nature of their discourse that is the core of our assumption here. 
%Our findings engender interesting potential research questions: Do we get similar user sentiments towards other non-Facebook privacy sensitive media? Does incorporating more data and application of machine learning based text classification approach guarantee successful prediction? For our future work we want to explore other sources where users discuss their Facebook user experience to get a comprehensive understanding. This however, is not feasible to answer in a single paper, since everyday more and more such platforms are emerging and also analysis of a particular site provides answers to problems of specific audience. Design and implementation of a text classifier, which will significantly reduce the human effort and increase data for further training, is also left as future work. Also, we would like to extend the knowledge gathered from this study to address more generic agenda, such as overall social media (not only Facebook) sentiment mining. We want to use more hand annotated data for future analysis as it will not only increase the accuracy but also help getting our domain specific sentiment.  
%The coding part is also vulnerable to noise because of the inherent fuzziness of comments and occasional lack of context, therefore the classification fully depends on the coder's discretion. 